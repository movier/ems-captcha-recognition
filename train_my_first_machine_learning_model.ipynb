{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train My First Machine Learning Model\n",
    "\n",
    "I'm always interested in machine learning since last year I learned the concept. After watched a lot of videos and read a bunch of posts, recently I trained my first machine learning model and it's really exciting.\n",
    "\n",
    "## Find a problem\n",
    "\n",
    "The first also the most important thing to train a model is to find a problem which is currently handled by human but could be solved by machine. If you are one of the human it will be great because you will be willing to save yourself a lot of time.\n",
    "\n",
    "I use [EMS](http://ems.com.cn)(Express Mail Service) a lot after my baby was born because I need to query milk powder from Germany(*Big thanks to my best friend in Germany*) and commodities from Amazon Japan. The stupid website asks every user to recognize a captcha before show their mail information. Thus I found my machine learning problem which is to recognize the captcha from their website. The captcha looks like this: \n",
    "\n",
    "![EMS captcha](unknow.jpg)\n",
    "\n",
    "To our human being it's an easy task. Believe it or not it's also a piece of cake to a computer thanks to machine learning.\n",
    "\n",
    "## Analysis the problem\n",
    "\n",
    "The captcha is always composed by six numbers and our goal is to recognize all the numbers from a captcha image which is a typical image classification problem. There is a question what's the categories? Categories are the whole possible result to a specific image classification problem. It seems reasonable to label them from 000000 to 999999. But we will need huge amount of traning data if we categories like this. Instead we chose to cut the captcha into six pieces which contain their own number. So our category will be 0 to 9. Pretty simple! We only need to recognize each piece of the captcha and combine their result together to get final result.\n",
    "\n",
    "We need to write a simple script to cut the captcha image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "name = \"unknow.jpg\"\n",
    "\n",
    "y = 0\n",
    "w = 13\n",
    "h = 20\n",
    "\n",
    "x = 5\n",
    "\n",
    "im = Image.open(name)\n",
    "for i in range(6):\n",
    "    x += w if i > 0 else 0 \n",
    "    region = im.crop((x, y, x + w, y + h))\n",
    "    resize = region.resize((128, 197), Image.BILINEAR)\n",
    "    segmentName = random.randint(1, 9999)\n",
    "    resize.save(\"%d.jpeg\" % segmentName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training data\n",
    "\n",
    "Our machine learning model needs to be fed by tranining data. How can we get data? It's always been a difficult problem for machine learning newbies. I use a most stupid method. Download a lot of captcha from their website and use their value for name. These captcha named with their content are the origin data. We need to preprocess those captcha and organize them correctly before we do training. \n",
    "\n",
    "We need to create ten directories with name from 0 to 9 and put each segment number cut from origin captcha into their corresponding directory. Here is the codes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "import os\n",
    "\n",
    "imageDir = \"./digit_images\"\n",
    "if not os.path.exists(imageDir):\n",
    "    os.makedirs(imageDir)\n",
    "\n",
    "for i in range(10):\n",
    "    dir = \"./%s/%d\" % (imageDir, i)\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "dataDir = \"./captcha/\"\n",
    "y = 0\n",
    "w = 13\n",
    "h = 20\n",
    "\n",
    "for name in os.listdir(dataDir):\n",
    "    x = 5\n",
    "    value = name.split(\".\")[0]\n",
    "    im = Image.open(dataDir + name)\n",
    "    for i in range(6):\n",
    "        x += w if i > 0 else 0 \n",
    "        region = im.crop((x, y, x + w, y + h))\n",
    "        resize = region.resize((128, 197), Image.BILINEAR)\n",
    "        segmentName = random.randint(1, 9999)\n",
    "        resize.save(\"./%s/%s/%d.jpeg\" % (imageDir, value[i], segmentName))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "With training data prepared we can train our model simply with a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=500 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/mobilenet_0.50_128 \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=mobilenet_0.50_128 \\\n",
    "  --image_dir=tf_files/flower_photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about the script above please check out [4. (Re)training the network](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3) from TensorFlow For Poets. The whole traning process should cost you dozens of seconds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use model to predict\n",
    "\n",
    "After training we could use our model to predict a segment number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'scripts/label_image.py --image=digit_images/0/155.jpeg.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "%run -i 'scripts/label_image.py --image=digit_images/0/155.jpeg'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
